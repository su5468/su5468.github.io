---
layout: posts
categories:
    - Study
title: (전공복습) 인공지능 4. 확률과 베이지안
---

# 차례

# 들어가기 전에
> 이 글은 컴퓨터학과 이중전공생으로서 배운 것들을 다시 한번 정리하고자 남기는 글입니다. 불완전한 기억 등의 이유로 오류가 있을 수 있으며, 참조 내지 이정표로만 사용해주세요.  
> 본 게시글은 고려대학교의 *인공지능* 강의를 기반으로 작성자의 추가적인 설명이 덧붙여진 글입니다. 또한 해당 강의는 UC 버클리 CS188을 기반으로 함을 밝힙니다.  

# 확률 이론(Probability Theory)

라플라스의 악마(Laplace's Demon)로 유명한 수학자이자 현대 확률 이론의 확립에 큰 공헌을 한 라플라스는 확률이론에 대해 *상식을 계산할 수 있도록 만든 것일 뿐*이라 칭했다. 우리는 확률 이론의 기초와, 매우 중요한 베이즈 정리(Bayes' Theorem), 그리고 나이브 베이지언 분류기에 대해 알아볼 것이다.  

## 확률변수(Random Variable)

확률변수란 불확실한 값을 표현하기 위한 변수이다. 주로 대문자로 나타내며, 특정 영역(Domain, 정의역)을 변수의 가능한 값으로 가진다. 이를테면 육면체 주사위를 하나 굴리는 경우, 그 결과값 $$D$$는 $$\{1, 2, 3, 4, 5, 6\}$$이라 할 수 있다. 파이썬의 `random.random()` 함수의 반환값 $$R$$은 $$[0, 1)$$의 범위를 갖는다. 이처럼 확률변수는 특정 범위를 지니게 된다.  
확률변수는 측정 가능한 함수(Measurable Function, 가측함수) $$X : \Omega \to E$$로 나타낼 수 있다. $$\Omega$$는 위에서 말한 가능한 사건들의 집합(정의역)이 된다. 이를테면 주사위 던지기에서 $$\Omega = \{1, 2, 3, 4, 5, 6\}$$이다. $$E$$는 그 사건이 발생할 확률을 나타내는 공간인데, 확률론의 특성 상 $$E$$의 범위는 $$[0, 1]$$이며 모든 확률의 합은 $$1$$이 되어야 한다.  

## 확률분포(Probability Distribution)

확률분포란 말 그대로 각 사건이 일어날 확률의 분포를 의미한다. 이산적인(Discrete) 값에 대한 분포는 이산 확률분포라 하고, 반대로 연속적인(Continuous) 값에 대한 분포는 연속 확률분포라 한다. 이산 확률분포는 표로도 나타낼 수 있다. 이를테면 아래는 정말 간단한 동전 던지기의 확률분포표이다. 이 분포표에 따라, 우리는 $$P(동전=앞면) = P(앞면) = 0.5$$이고 $$P(동전=뒷면) = P(뒷면) = 0.5$$라고 말할 수 있다.  

|동전|확률|
|---|---|
|앞면|0.5|
|뒷면|0.5

### 결합분포(Joint Distribution)

결합분포란 여러 개의 확률변수가 결합한 분포를 의미한다. 동전을 두 개 던지는 경우를 생각해보자. 이때 확률변수는 동전1과 동전2, 두 개가 된다. 따라서 나올 수 있는 경우의 수는 $$2 \times 2 = 4$$개일 것이다. 결합분포는 이처럼 여러 개의 확률변수에 대한 분포를 의미한다. 결합분포는 $$P(동전1=앞면, 동전2=뒷면) = P(앞면, 뒷면) = 0.25$$와 같이 나타낼 수 있다.  

|동전1|동전2|확률|
|---|---|---|
|앞면|앞면|0.25|
|앞면|뒷면|0.25|
|뒷면|앞면|0.25|
|뒷면|뒷면|0.25|

위 분포표를 보고, 동전1은 앞면, 동전2는 뒷면일 확률은 $$0.25$$라는 것을 알 수 있다. 동시에, 동전1이 앞면일 확률은 $$0.25 + 0.25 = 0.5$$라는 것도 알 수 있다.  
결합분포를 분포표로 나타낸다고 할 때, 이처럼 각 확률변수의 가능한 사건들의 개수를 전부 곱하게 된다. 따라서 실질적으로 결합분포 전체를 분포표로 그리는 것은 굉장히 힘들게 된다.  

### 주변분포(Marginal Distribution)

주변분포는 결합분포에서 반대로 몇 개의 확률변수를 제거한 분포를 이야기한다. 예를 들어 위 동전 2개의 결합분포표는, 동전1에 대한 주변분포와 동전2에 대한 주변분포로 쪼갤 수 있다. 이를 주변화(Marginalization)라 한다.  

### 조건부 확률(Conditional Probability)

조건부 확률이란 어떤 사건이 일어났을 때, 다른 확률변수의 사건이 일어날 확률을 말한다. $$P(a \vert b)$$로 표기하고, 이는 사건 $$b$$가 발생했을 때, 사건 $$a$$가 발생할 확률을 의미한다. 조건부 확률 $$P(a \vert b) = {P(a, b) \over P(b)}$$로 계산한다. 우변의 식을 말로 풀어보자면 사건 $$b$$가 벌어졌을 때, 사건 $$a$$와 $$b$$가 모두 벌어질 확률이므로 퍽 직관적이다.  

## 확률적 추론(Probabilistic Inference)

알려진 확률들을 통해 원하는 확률을 구하는 것을 확률적 추론이라 한다. 이를테면 상기 조건부 확률을 구하는 공식 역시 알려진 $$P(a, b)$$와 $$P(b)$$를 바탕으로 $$P(a \vert b)$$를 구하는 확률적 추론 과정이라 할 수 있다.  
이와 같은 확률적 추론 과정은 어떤 단서가 주어졌을 때의 에이전트의 믿음(Belif)이라 볼 수 있다. 새로운 단서가 주어지면 추론의 값은 변화한다. 내일 비가 올까? 알 수 없다. 오늘 구름이 많이 꼈다면? 믿음을 증가하는 쪽으로 수정할 것이다. 곧 장마철이라면? 믿음은 더 증가할 것이다.  

### 곱셈법칙(Product Rule)

확률의 곱셈법칙이란 결합분포를 구하기 위한 공식을 의미한다. $$P(x, y) = P(x \vert y)P(y)$$인데, 이는 조건부 확률의 정의에서 쉽게 유도할 수 있다.  

1. 조건부 확률의 정의에 따라 $$P(x \vert y) = {P(x, y) \over P(y)}
2. 양변에 $$P(y)$$를 곱하면 $$P(x \vert y)P(y) = P(x, y)$$

### 연쇄법칙(Chain Rule)

확률의 연쇄법칙이란 위의 곱셈법칙을 조금 더 일반화한, 여러 개의 결합분포를 구하기 위한 공식을 의미한다. 예를 들어 3개의 확률변수를 지닌 $$P(x, y, z) = P(x)P(y|x)P(z\vert y, x)$$이다. 조금 복잡해 보일 수 있는데, $$x$$의 확률($$P(x)$$), $$x$$일 때 $$y$$일 확률($$P(y \vert x)$$), $$x$$고 $$y$$일 때 $$z$$의 확률($$P(z \vert x, y)$$)의 곱이다. 즉, 사건 1이 일어날 확률, 그리고 사건 1이 일어났을 때 2도 일어날 확률, 그리고 사건 1, 2가 일어났을 때 3도 일어날 확률, ...으로 확장되는 것이다. $$n$$개의 사건에 대해 일반화하면 아래와 같다.  

- $$P(x_1, x_2, ..., x_n) = \prod\limits_i P(x_i \vert x_{<i})$$

*(참고로, $$\prod$$는 $$\sum$$과 비슷한데, 속한 모든 항들을 곱하라는 의미이다.)*

## 베이즈 정리(Bayes' Theorem)

베이즈 정리는 사전확률에서 사후확률을 구하는 공식을 의미한다. 사전확률과 사후확률이란 무엇일까?  
사전확률(Prior Probability)이란 말 그대로 기존에 알던 확률을 말한다. 우리가 어떤 사람을 보았다고 하자. 그가 남자일 확률을 어떻게 계산하겠는가? 기본적으로 아무 정보가 없다면, 대략적으로 반반으로 예측할 수 있다. 이 경우 확률은 $$0.5$$이다.  
사후확률(Posterior Probability)이란 추가적인 단서가 주어져서 업데이트된 확률을 의미한다. 우리가 그 사람을 본 곳이 예를 들어 군부대라고 하자. 그가 남자일 확률을 그대로 $$0.5$$로 두는 것은 불합리해 보인다. 단서가 주어졌기 때문에 이를 기반으로 확률을 업데이트할 수 있는 것이다.  
위와 같은 예시에서, 기존의 $$P(남자)$$는 사전확률이고, $$P(남자 \vert 군부대)$$는 사후확률이 된다. 추가로, $$P(군부대 \vert 남자)$$에 대해서도 이야기할 수 있는데, 이는 가능도(Likelihood, 우도)라고 부른다.  

어쨌든, 베이즈 정리는 사전확률(단서가 없을 때의 확률)에서 사후확률(단서가 있을 때의 확률)로 업데이트를 하기 위한 공식인데, 아래와 같다.  

- $$P(A \vert B) = {P(B \vert A) P(A) \over P(B)}$$

즉 $$P(A \vert B)$$를 구하기 위해서는 $$P(B \vert A)$$, $$P(A)$$, 그리고 $$P(B)$$가 필요한데, 이때 $$P(B)$$를 계산해야 하는 문제들이 있는 경우가 많다. 이 경우에, 베이즈 정리는 아래와 같이 쓸 수도 있다.  

- $$P(A \vert B) = {P(B \vert A) P(A) \over P(A,B) + P(\overline A , B)} = {P(B \vert A) P(A) \over P(B \vert A)P(A) + P(B \vert \overline A)P(\overline A)}$$

확률 $$P(B)$$를 구하기 위해, $$A$$면서 $$B$$인 경우와 $$A$$가 아니면서 $$B$$인 경우로 분리하고, 두 개의 확률에 각각 확률의 곱셈법칙을 적용한 것이다. 위 공식에서는 사건 $$A$$의 확률변수를 이진적인 것으로 보았지만, 3개 이상의 값을 가질 때도 위와 같은 방식으로 분리해서 계산할 수 있다.  

인공지능의 관점에서, 베이즈 정리는 어떤 데이터를 단서로 삼았을 때, 예측하고자 하는 사건이 일어날 확률을 구하는 데에 사용할 수 있다. 이 경우 사전확률은 아무 데이터가 없을 때 사건의 확률, 사후확률은 데이터를 고려하였을 때 사건의 확률, 가능도는 해당 데이터가 예측하고자 하는 사건을 바탕으로 표집되었을 확률을 의미한다.  

## 최대가능도법(MLE)

최대가능도법 또는 최대우도법(Maximum Likelihood Estimation, MLE)은 말 그대로 분류를 위해 가능도(Likelihood)를 최대로 하는 클래스가 어떤 것인지 확인하는 방법을 의미한다. 전술했든 가능도는 $$P(단서 \vert 사건)$$인데, 이 경우에는 $$P(피처 \vert 클래스)$$라고 볼 수 있다. 즉, MLE는 $$P(X \vert \theta)$$를 최대로 만드는 클래스(레이블) $$\theta$$를 찾는 게 목적이다. 수식으로는 이를 $$\theta_{\mathrm{MLE}} = \arg \max _\theta P(X \vert \theta)$$라 표현할 수 있다.  

## 최대사후법(MAP)

반면, 최대사후법(Maximum A Posteriori)는 가능도 대신 사후확률(Posterior Probability)를 최대화하는 방법이다.  MLE가 주어진 데이터가 어떤 클래스에서 나왔을 확률이 제일 높은지 찾는 방법이라면, MAP는 주어진 데이터에서 어떤 클래스가 나올 확률이 제일 높은지 찾는 방법이다. 다시 말해, MLE는 클래스에서 데이터가 차지하는 비중이 제일 높은 걸 고르는 거고, MAP는 데이터에서 클래스가 차지하는 비중이 제일 높은 걸 고르는 것이다. 따라서 수식으로는 $$\theta_{\mathrm{MAP}} = \arg \max _\theta P(\theta \vert X)$$이다. 이때, $$\theta$$는 클래스, $$X$$는 대상 데이터의 피처들이 된다.  

이때, MAP는 베이즈 정리에 의하여 $$\arg \max _\theta {P(X \vert \theta) P(\theta) \over P(X)}$$로 표현될 수 있다. 그런데 우리는 하나의 대상(데이터 포인트)에 대해 이야기하고 있으므로, 피처 $$X$$는 사후확률을 계산할 클래스가 바뀌더라도 항상 같고, 따라서 분모의 $$P(X)$$는 상수라고 생각하고 비교해도 문제가 없다. 즉, 최대사후법은 $$\arg \max _\theta P(X \vert \theta) P(\theta)$$라고 해도 무방하다. 이때 로그를 씌우면 $$\arg \max _\theta \log P(X \vert \theta) + \log P(\theta)$$로 나타낼 수 있다.  

참고로, 모든 클래스가 등장할 확률이 동일하다면(Uniform Distribution), $$P(\theta)$$는 상수로 볼 수 있고, 따라서 MAP를 구할 때 해당 항을 생략할 수 있다. 그럼 $$\theta_{\mathrm{MAP}} = \arg \max _\theta \log P(X \vert \theta)$$로 나타낼 수 있는데, 이건 (로그를 씌운) MLE와 같다. 즉, 균등분포에서 MAP는 MLE와 같다.  

# 나이브 베이지언 분류기(Naive Bayes Classifier)

나이브 베이지언 분류기는, 말 그대로 분류기(Classifier)이고, 분류기는 주어진 대상을 가장 확률이 높은 클래스로 배정하는 역할을 한다. 이를테면 스팸 메일 분류기는 어떤 메일이 스팸 클래스에 속하는지, 정상 클래스에 속하는지 분류한다. 반드시 클래스가 두 개여야 하는 것은 아니다. 이를테면 문서의 주제 분류와 같이 클래스가 여러 개인 경우에도 분류기를 사용할 수 있다.  

일반적으로 나이브(Naive)하다는 것은 우리말로 *순진하다* 내지는 *소박하다*라는 의미를 지닌다. 조금 더 구체적으로는 참이 아닐 수 있는 가설을 전제하는 것을 의미하는데, 나이브 베이지언 분류기는 각 사건(피처)들이 레이블(클래스)에 대해 조건부 독립이라고 가정한다.  

## 조건부 독립(Conditional Independence)

조건부 독립이란 세 개의 확률변수 $$X$$, $$Y$$, $$Z$$에 대해 $$\forall x, y, z :P(x,y \vert z) = P(x \vert z) P(y \vert z)$$를 만족하는 것을 의미한다(이때 $$x, y, z$$는 $$X, Y, Z$$의 가능한 값). 또한, $$X$$와 $$Y$$가 $$Z$$에 대해 조건부 독립이라면 $$X \perp\!\!\!\perp Y \vert Z$$로 표기할 수 있다.  
수식만 봐서는 조건부 독립이 어떤 의미를 지니는지 파악하기 어려울 수 있다. 일반적인 독립(무조건부 독립)은 두 사건이 아무 관계가 없음을 나타낸다. 예를 들어, 동전을 두 번 던진다면, 처음의 동전 던지기와 그 다음 동전 던지기는 아무런 확률적 연관이 없다. 한편, 조건부 독립은 두 사건이 특정 조건 하에서만 독립임을 의미한다. 이를테면 비, 천둥, 번개의 관계를 살펴보자. 비와 번개는 독립이 아니다. 비가 오면 번개가 칠 확률이 올라가기 때문이다. 하지만 비와 번개의 관계는 천둥이라는 조건이 붙으면 사라진다. 천둥이 있다는 전제 하에, 비가 내리든 내리지 않든 번개는 무조건 친다. 반대로 천둥이 없다는 전제 하에, 비가 내리든 내리지 않든 번개는 무조건 치지 않는다. 비와 번개는 더이상 관계를 가지지 못하는 것이다. 이처럼 특정 조건 하에 두 확률변수가 독립이 된다면 이를 조건부 독립이라 한다.  

한편, 조건부 독립 $$\forall x, y, z :P(x,y \vert z) = P(x \vert z) P(y \vert z)$$에서, 우리는 $$\forall x,y,z: P(x \vert z, y) = P(x \vert z)$$를 유도할 수 있다. 말로 풀어보자면 비가 오면서 천둥이 칠 때 번개가 칠 확률은 그냥 천둥이 칠 때 번개가 칠 확률과 같다(비가 번개에 영향을 주지 않는다).  

## 나이브 베이지언 분류기의 계산

그래서 나이브 베이지언 분류기는 어떤 식으로 작동하는가? 우선 우리가 구하고 싶은 것은 $$\arg \max _j P(c_j \vert X_1, ..., X_k)$$로, 이는 주어진 피처 $$X_1, ..., X_k$$에 대해, 거기서 가장 나올 확률이 높은 클래스가 무엇인지 찾는 것을 의미한다.  

1. 베이즈 정리에 따라, $$P(c_j \vert X_1, ..., X_k) = {P(X_1, ..., X_k \vert c_j) P(c_j) \over P(X_1, ... X_k)}$$이다.
2. 클래스가 변하더라도 특정 데이터의 피처는 변하지 않으므로 상수 취급할 수 있다. 따라서 값을 비교하는 데에 필요하지 않으므로 $$\arg \max _j {P(X_1, ..., X_k \vert c_j) P(c_j) \over P(X_1, ... X_k)} = \arg \max _j P(X_1, ..., X_k \vert c_j) P(c_j)$$이다.
3. 각 피처 $$X_1, ..., X_k$$를 클래스에 대해 조건부 독립이라고 가정하였으므로, 조건부 독립의 정의에 의해 $$P(X_1, ..., X_k \vert c_j) = \prod\limits_{i=1}^k P(X_i \vert c_j)$$이다.
4. 결과적으로 우리가 구하고자 하는 것은 $$\arg \max _j P(c_j) \prod\limits_{i=1}^k P(X_i \vert c_j)$$이다.
5. 이를 구하기 위해서는 각 클래스의 사전확률 $$P(c_j)$$와, 피처 $$X_i$$에 대한 가능도 $$P(X_i \vert c_j)$$가 필요하다.
6. 우선 $$P(c_j) = {N(c_j)\over N}$$로, 이때 $$N(c_j)$$는 클래스 $$c_j$$에 속한 데이터의 개수이고, $$N$$은 전체 데이터의 개수이다.
7. 또한 $$P(X_i \vert c_j) = {N(X_i, c_j) \over N(c_j)}$$로, 이때 $$N(X_i, c_j)$$는 클래스 $$c_j$$에 속하면서 $$X_i$$를 지닌 데이터의 개수이다.

## Laplace Smoothing

나이브 베이지언 분류기는 학습에 사용된 데이터의 분포에 기반해서 작동한다. 따라서 기존 데이터에서 보지 못한 특징을 가진 데이터는 제대로 분류하지 못한다. 이러한 문제를 완화하기 위해 Laplace Smoothing을 사용할 수 있다.  
Laplace Smoothing은 확률을 구할 때, 분자와 분모에 각각 임의의 상수를 더하는 방법이다. 즉, 확률 $$P = {N_1 \over N_2}$$에 대해, $$P = {N_1 + \alpha \over N_2 + \beta}$$로 만드는 것이다. 이를 통해 지나치게 큰 확률은 조금 줄이고, 처음 보는 데이터도 안정적인 확률을 갖도록 만들어줄 수 있는데, $$\alpha$$와 $$\beta$$는 사전지식에 따라 결정할 수도 있고, 학습 과정에서 설정하도록 할 수도 있다.  

## 로그 나이브 베이지언

나이브 베이지언 분류기에 로그를 씌워 $$\arg \max _j P(c_j) \prod\limits_{i=1}^k P(X_i \vert c_j) = \arg \max _j \log P(c_j) +  \sum\limits_{i=1}^k \log P(X_i \vert c_j)$$로 변환해도 대소관계는 유지된다. 로그를 씌우면 계산이 간단해질 뿐 아니라 소수점 언더플로우 문제도 피할 수 있다.  
*(참고로, 소수점 언더플로우란 확률을 계속 곱해서 값이 계산, 유지하기 어려울 정도로 작아지는 문제를 말한다)*  

## 장단점

### 장점

나이브 베이지언 분류기의 장점은 아래와 같다.  

- 간단하고 빠르다. 한번만 데이터셋을 세면 반복 없이 계산할 수 있다.
- 모델이 간단하다. 모델의 크기가 피처와 클래스의 개수 곱으로 정의된다.
- 수학적으로 잘 작동한다.
- 의존적인 피처가 별로 없는 희소한 데이터에서도 잘 작동한다.

### 단점

반대로 단점은 아래와 같다.  

- 피처가 조건부 독립이 아닌 경우 특히 오류와 편향에 약해진다.
- 데이터셋에서 패턴을 찾아내지는 못한다.
- 상기한 이유로, 다른 방법에 비해 정확도가 떨어질 수 있다.

# 정리

오늘은 [확률론](#확률-이론probability-theory)과 [나이브 베이지언 분류기](#나이브-베이지언-분류기naive-bayes-classifier)에 대해서 알아보았다. 확률의 기초야 당연히 중요하고, [베이즈 정리 전반](#베이즈-정리bayes-theorem), [MLE](#최대가능도법mle)와 [MAP](#최대사후법map) 등은 자주 언급되는 중요한 방법론이니 알고 있자.  

다음에는 결정 트리(Dicision Tree), 군집화(Clustering) 등에 대해 알아볼 예정이다.  