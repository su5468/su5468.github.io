---
layout: posts
categories:
    - Study
title: (전공복습) 데이터과학 0. 기초 및 사전지식
---

# 차례

- [차례](#차례)
- [들어가기 전에](#들어가기-전에)
- [데이터과학 생애주기(Data Science Lifecycle)](#데이터과학-생애주기data-science-lifecycle)
- [수학과 numpy 기초](#수학과-numpy-기초)
  - [평균(Mean)과 분산(Variance)](#평균mean과-분산variance)
  - [배열(Array)](#배열array)
    - [행렬곱(Matrix Product)](#행렬곱matrix-product)
    - [역행렬(Inverse Matrix)](#역행렬inverse-matrix)
- [조사 기초](#조사-기초)
  - [표집(Sampling)](#표집sampling)
    - [서베이(Survey)와 센서스(Census)](#서베이survey와-센서스census)
    - [Chance Error와 Bias](#chance-error와-bias)
      - [대표적인 편향](#대표적인-편향)
    - [표집의 종류](#표집의-종류)
      - [비확률표집(Non-Probability Sampling)](#비확률표집non-probability-sampling)
      - [확률표집(Probability Sampling)](#확률표집probability-sampling)
  - [Designed Experiment](#designed-experiment)
    - [Randomized Controlled Trial(RCT)](#randomized-controlled-trialrct)
    - [관찰연구(Observational Study)](#관찰연구observational-study)
    - [A/B 테스트(A/B Testing)](#ab-테스트ab-testing)
- [정리](#정리)

# 들어가기 전에
> 이 글은 컴퓨터학과 이중전공생으로서 배운 것들을 다시 한번 정리하고자 남기는 글입니다. 불완전한 기억 등의 이유로 오류가 있을 수 있으며, 참조 내지 이정표로만 사용해주세요.  
> 본 게시글은 고려대학교의 *데이터과학* 강의를 기반으로 작성자의 추가적인 설명이 덧붙여진 글입니다.  

# 데이터과학 생애주기(Data Science Lifecycle)

![데이터과학 생애주기]()  

데이터과학은 4가지 단계의 유기적 연결로 볼 수 있다.  

1. **질문하기**: 해결하고자 하는 문제를 생각한다. 만약 데이터를 사용하지 않고 해결 가능한 문제라면 그냥 해결하면 되지만, 데이터과학의 힘이 필요한 경우, 어떤 데이터를 이용할지 생각해야 한다.
2. **데이터 얻기**: 데이터를 수집하고 그 데이터가 모집단을 잘 대표하는지 생각해볼 필요가 있다.
3. **데이터 이해하기**: EDA 등의 방법으로 데이터를 이해하기 위해 노력한다.
4. **세계를 이해하기**: 보고서를 작성하거나, 의사결정에 이용하거나, 해결책을 제시하는 등... 데이터를 기반으로 문제를 해결한다.

이 단계들이 반드시 순서대로 진행되지 않는 것에 유의하자. 실제로 이 과정은 유기적으로 반복되고, 특히 그래프의 시작 지점이 2개인 것에 주의를 기울여야 한다. 질문이 반드시 데이터에 선행하는 것은 아니고, 반대 역시 마찬가지다.  

# 수학과 numpy 기초

데이터과학을 위한 매우 기초적인 수학이다. 숙지하도록 하자.  
또한, 이 챕터에서는 `numpy` 역시 다루도록 할텐데, `numpy`란 파이썬에서 수치 계산을 효율적으로 하기 위한 라이브러리이다. 특히 배열(`np.array`)을 통해 행렬 연산을 쉽게 지원하므로 꼭 알아두도록 하자. 참고로 `numpy`는 일반적으로 `np`라는 별칭으로 임포트된다.  

```python
import numpy as np
```

*(이 챕터에서는 행렬에 대한 아주 기초적인 지식은 알고 있다고 가정하겠다.)*  

## 평균(Mean)과 분산(Variance)

**평균(Mean)**이란 무엇인가? 여러 개의 값을 대표하는 방법 중 하나를 의미한다. 여기서 우리는 좁게, 산술 평균(Arithmetic Mean)을 의미하는데, 모든 값들을 더해서 그 값의 개수로 나누어준 것을 이야기한다. 일반적으로 모집단 평균은 $$\mu$$로 표기하고, $$\mu = {1 \over N} \sum\limits_{i=1}^N x_i$$이다(단, $$N$$은 모집단의 크기).  

**분산(Variance)**은 값들이 흩어져있는 정도를 의미한다. 분산에 루트를 씌우면 **표준편차(Standard Deviation)**라 부르고, 이말인즉슨 표준편차의 제곱이 분산이라는 의미이다. 표준편차는 $$\sigma$$로 표기하므로 분산은 $$\sigma^2$$이고, 구하는 공식은 $$\simga^2 = {1 \over N}\sum\limits_{i=1}^N (x_i - \mu)^2$$이다. 말로 풀어서 설명하자면, 모든 값들에 대해, 평균과의 차이를 구하고, 그것들을 제곱해서 더한 것이다.  
분산을 구할 때 차이들을 제곱하는 이유는 평균의 정의 상 모든 값들과 평균의 차를 전부 더하면 $$0$$이 나오기 때문이다.  

평균과 분산은 `numpy`에서 `np.mean()`과 `np.var()`를 통해 계산한다.  

## 배열(Array)

배열이 대략 어떤 자료구조인지는 알고 있으리라 생각하겠다. 모른다면, 파이썬을 알고 있다면 리스트와 비슷한 것으로 생각하면 되고, 아니라면 이 글을 읽는 동안은 행렬을 표현하기 위한 방법 정도로 이해해도 괜찮다.  
*(구체적인 내용은 검색해보거나 추후 등장할 자료구조와 같은 게시글을 기다리라.)*  

`numpy`에서 배열은 `np.array()`로 만들 수 있다. 예를 들어, 아래 코드는 이차원 배열을 만드는 예제이다.  

```python
arr = np.array([
    [1, 2, 3],
    [4, 5, 6]
])
```
### 행렬곱(Matrix Product)

배열의 곱셈을 위한 연산자는 `*`와 `@`이 있다. 전자는 배열의 각 원소끼리 곱하는 데에 사용된다. 후자는 행렬곱을 하는 데에 사용된다.  

행렬곱이란 무엇인가? 두 개의 행렬을 곱하는 방법이다. 행렬곱에 대해 간단하게만 짚고 넘어가겠다. 우선 행렬곱은 모든 종류의 행렬에 대해 성립하지 않는다. $$m \times n$$ 크기의 행렬에 대해, $$n \times r$$ 크기의 행렬과의 곱셈이 정의되는데, 즉 행렬곱을 위해서는 앞쪽 행렬의 열의 수가 뒤쪽 행렬의 행의 수와 같아야 한다. 그리고 이 행렬곱의 결과는 $$m \times r$$ 크기의 행렬이 된다.  
또한, 행렬곱의 결과로 나오는 행렬의 각 성분은 앞쪽 행렬의 행과 뒤쪽 행렬의 열을 모두 곱해서 더한 것이다. 수학적으로 두 행렬 $$\mathbf{A}$$와 $$\mathbf{B}$$의 곱은 $$(\mathbf{A}\mathbf{B})_{ij} = \sum\limits_{k=1}^n \mathbf{A}_{ik} \mathbf{B}_{kj}$$이다.  
참고로, 행렬은 이처럼 크기가 알맞은 경우에만 정의되기 때문에 교환법칙이 성립하지 않는다. 즉, 일반적으로 $$\mathbf{A}\mathbf{B} \ne \mathbf{B}\mathbf{A}$$이다.  

### 역행렬(Inverse Matrix)

`numpy`의 `np.linalg.inv()`는 역행렬을 구하는 함수이다. 역행렬이란 행렬에 대한 곱셈의 역원을 말한다. 쉽게 풀어서 설명하자면, 어떤 행렬에 곱해서 **항등행렬(Identity Matrix)**이 나오는 행렬을 말한다.  
맙소사, 항등행렬은 또 무엇일까? 항등행렬은 단위행렬이라고도 부르는데, 보통 $$I$$로 표기한다. 단위행렬은 행과 열의 길이가 같은 정사각행렬이면서, 행과 열의 번호가 같은 성분(어려운 말로 주대각성분이라 한다)만 $$1$$이고 나머지는 $$0$$인 행렬을 의미한다. 예를 들어 아래는 $$2 \times 2$$ 크기의 항등행렬이다.  

- $$I_2 = \begin{bmatrix} 1 & 0 \\ 0 & 1\end{bmatrix}$$

항등행렬은 행렬곱(정확히는 정사각행렬의 행렬곱)에 대한 항등원이다. 항등원이란 어떤 값이든 연산을 해도 그대로 유지되는 값을 말한다. 예를 들어 어떤 수에든 $$0$$을 더하면 그대로 그 수가 나오므로 덧셈의 항등원은 $$0$$이고, 어떤 수에든 $$1$$을 곱하면 그대로 그 수가 나오므로 곱셈의 항등원은 $$1$$이다. 이처럼 어떤 정사각행렬에 대해 같은 크기의 항등행렬을 곱하면 그 행렬이 그대로 나온다.  

다시 돌아가서, 역행렬은 무엇일까? 항등행렬이 항등원이라면 역행렬은 역원이다. 역원이란 연산을 하면 항등원이 나오는 값을 의미한다. 예를 들어 어떤 수 $$n$$에 대한 곱셈의 역원은 $$1 \over n$$이다. 그리고 이를 역수라고 부른다. 덧셈에 대한 역원은 무엇일까? $$-n$$이다. 즉 (정사각)행렬 $$\mathbf{A}$$에 그 역행렬 $$\mathbf{A}^{-1}$$을 곱하면 반드시 항등행렬이 나온다. 행렬곱의 역수라고 할 수 있는 것이다.  

*(항등원이니 역원이니 하는 내용은 이산수학 등 다른 게시글에서도 다뤄질 예정이다.)*  

# 조사 기초

표집 및 기초적인 조사 방법에 대해 알아보자.  
*(참고로, 이러한 조사 및 통계에 관한 내용은 매우 나중에 다루게 될 예정인 사회조사방법 및 사회통계 게시글에서 더욱 구체적으로 다루겠다.)*  

## 표집(Sampling)

우리의 연구 대상은 때때로 너무나 크다. 예를 들어 한국인의 식생활에 관련된 분석을 하고 싶다고 하자. 그렇지만 5000만 한국인 전체의 식생활 데이터를 얻는 것은 매우 어렵다. 그렇기 때문에 우리는 5000만 한국인 전체가 아니라, 그 중 일부만 뽑아서 조사대상으로 삼게 된다.  
이때, 우리 질문의 대상(이 경우, 한국인 5000만명)을 **모집단(Population)**이라 한다. 일반적으로 모집단 전체에 대한 데이터를 확보하는 것은 어렵다. 그렇기 때문에, 모집단에서 일부를 추출하여 데이터를 확보하게 되는데, 이때 그 일부를 **표본(Sample)**이라 부르고, 모집단에서 표본을 추출하는 것을 **표집(Sampling)**이라 부른다. 그리고 표집에 필요한 리스트를 **표집틀(Sampling Frame)**이라 한다.  
예를 들어, 한국인의 식생활에 대해 분석하려고 한다고 했을 때, 전체 한국인 5000만명에 대한 전수조사가 어려워 `010-0000-0000`에서 `010-9999-9999` 중 100개의 번호를 뽑아 통화를 돌려 설문조사를 진행했다고 하자. 이때 우리는 아래와 같이 말할 수 있다.  

- **모집단**은 한국인 5000만명이다.
- **표집틀**은 `010-0000-0000`에서 `010-9999-9999` 번호를 가진 사람들이다.
- **표본**은 표집틀에서 뽑힌 100명의 사람들이다.

이때, 중요한 것은 *표집틀이 모집단에 부합해야 한다*는 것이다. 위 예시의 표집틀은 모집단에 부합하는가? 모든 대한민국 사람들이 휴대전화를 가지지는 않는다는 점, 모든 휴대전화가 `010`으로 시작하지 않는다는 점, 외국인이 한국에서 번호를 개통했을 수도 있다는 점 등을 미루어 보았을 때, 표집틀과 모집단 사이에 불일치가 존재함을 알 수 있다. 이 경우 우리는 엉뚱한 표집을 했다고 말할 수도 있다.  
이와 관련된 유명한 예시가 바로 미국의 1936년 대선(루즈벨트 v.s. 랜던)이다. 당시 유명한 매거진이었던 Literary Digest는 랜던의 승리를 예상했다. 그러나 실제 결과는 루즈벨트의 압승이었는데, 이러한 차이의 이유는 Literary Digest에서 전화번호부와 매거진 구독자, 컨트리 클럽(쉽게 말해 골프클럽 같은) 가입자 목록을 표집틀로 삼았기 때문이다. 당시 시대상을 고려한다면 이러한 표집틀은 중산층 이상의 미국인들만을 대표하고 있었고, 따라서 공화당(보수) 소속의 랜던을 향한 표가 과대평가된 것이다.  

### 서베이(Survey)와 센서스(Census)

서베이란 조사를 위한 일련의 질문들을 폭넓게 가리키는 말이다. 한편, 센서스란 전수조사를 의미한다. 즉, 모집단을 대상으로 한 서베이를 센서스라고 볼 수 있다. 인구주택총조사와 같은 것들이 센서스의 예시가 된다.  

### Chance Error와 Bias

당연한 이야기지만, 표본은 모집단보다 더 부정확하다. 일부를 가지고 전체를 예측해야 하기 때문이다. 따라서 오류는 필연적인데, 이러한 오류를 두 가지로 구분할 수 있다.  
첫째는 **Chance Error**이다. Chance Error는 쉽게 말해 우연히 발생하는 오류이다. 표본을 가지고 모집단의 성질을 예측하려 하면 어떤 방향이든 오류가 발생할 수 있다. 예를 들어 우리 반 30명의 점수 평균을 10명으로 예측한다고 하자. 10명의 평균 점수가 86점이라면, 실제 30명의 평균 점수는 이보다 높을 수도 낮을 수도 있다. 이처럼 표본조사의 필연적인 오류가 Chance Error이다. 모든 방향으로 발생하고, 상대적으로 별 문제가 되지 않는다.  
둘째는 **Bias**이다. 우리말로는 편향이라고 주로 하는데, 특정 방향으로 치우친 오류이다. 예를 들어 우리 반 30명의 점수 평균을 예측하기 위해 나와 같은 학원에 다니는 10명의 점수를 사용했다고 하자. 일반적으로 학원에 다니는 아이들이 그렇지 않은 아이들보다 점수가 높을 것이므로, 실제 30명의 평균은 예측값보다 낮을 확률이 높다. 모든 방향으로 발생할 가능성이 동일한 Chance Error와 달리, 편향은 이처럼 한 방향으로 치우쳐 있기 때문에 더 큰 문제가 된다. 

#### 대표적인 편향

몇 가지 대표적인 편향에는 아래와 같은 것들이 있다.  

- **선택 편향(Selection Bias)**: 표본이 잘못 선택되어 특정 집단을 과대/과소평가하는 경우이다. 모집단에 부합하는 표집틀을 사용하고 제대로 된 표집 방법을 선택하면 회피할 수 있다.
- **응답 편향(Response Bias)**: 사람들은 때때로 정직하게 응답하지 않는다. 예를 들어 사회적 바람직성(Social Desirability) 편향이 있는데, 문항에 솔직하게 응답하는 대신 사회적으로 옳게 느껴지는 방향으로 응답하는 경향을 의미한다.
- **무응답 편향(Non-Response Bias)**: 사람들은 때때로 아예 설문을 거부한다. 차라리 모두들 공평하게 응답을 안 하면 모를까, 어떤 경우에는 응답자와 무응답자 집단 사이에 중요한 차이가 있기도 한다. 이를테면 이민이나 성평등과 같은 사회 현안에 대한 설문은 그 문제에 관심 있는 사람들이 더 열심히 응답할 것이다.

### 표집의 종류

표집을 하는 방법에는 여러가지가 있다. 여러 표집 방법을 우선 두 가지로 나누어 볼 수 있는데, 바로 확률표집과 비확률표집이다.  

#### 비확률표집(Non-Probability Sampling)

비확률표집이란 모집단의 각 대상이 표본으로 추출될 확률을 알 수 없는 표집방법을 의미한다. 예를 들어, **편의표집(Convinience Sampling)**은 그냥 가용한 표본을 그대로 표집하는 방법이다. 집 앞 거리에 나가서 지나다니는 사람을 눈에 띄는 대로 붙잡고 설문조사를 한다면 편의표집이다. 말 그대로 조사자가 편한 표집이다. 다만, 이런 편의성의 대가로 대표성은 떨어지게 된다. 편향이 존재할 확률이 높기 때문이다.  

또다른 비확률표집 방법은 **할당표집(Quota Sampling)**이다. 편의표집을 약간 개선한 방법으로, 모집단을 특성에 따라 비율을 나누고 그 안에서 편의표집을 하는 방법이다. 예를 들어 오늘날 대한민국의 인구 구성비는 유소년인구가 10%, 생산가능인구가 70%, 노령인구가 20%이다. 그렇다면 표집도 1:7:2의 비율로 진행하는 것이 더 합리적이지 않을까? 이런식으로 편의표집을 약간이나마 개선한 방법이 할당표집이다.  

위와 같은 비확률표집은 결과의 일반화가 어렵다는 단점이 있다. 표본이 모집단을 잘 대표하려면 전술한 편향(Bias)가 최대한 없어야 하는데, 비확률표집은 기본적으로 표집 방법이 확률론적이지 않기 때문이다. 하지만 표집틀 확보가 불가능한 등 확률표집이 어려운 상황에 사용할 수 있는 방법이기도 하다.  

#### 확률표집(Probability Sampling)

확률표집이란 비확률표집과 반대로 가능한 모든 표본이 표집될 확률을 계산할 수 있는 표집 방법을 의미한다. 대표적으로 **단순무작위표집(Simple Random Sampling, SRS)**이 있다. 단순무작위표집은 그 이름처럼 흔히 생각할 수 있는 랜덤 뽑기인데, 균등 무작위(Uniform Random)이고, 일반적으로 비복원(Without Replacement)이다.  

- **균등 무작위(Uniform Random)**란 모든 경우가 나올 확률이 모두 균등하다는 것을 의미한다.
- **비복원(Without Replacement)**이란 한번 표집된 사람이 다시 표집될 수 없다는 것을 의미한다.
  - 예를 들어, 100명의 표본을 뽑는데, 같은 사람이 두 번 표집되는 것은 부자연스러운 부분이 있다.

모든 경우의 수가 나올 확률이 같기 때문에, 다음의 예시는 단순무작위표집이 *아니다*: 100명의 사람 중 10명을 뽑기 위해, 100명에게 1번부터 100번의 번호를 부여한 뒤, 0부터 9까지의 숫자 중 하나를 고르고, 고른 숫자를 일의 자리 수로 하는 사람만 표집한다. 예를 들어, 3을 고르면 3, 13, 23, ..., 93번을 표집한다.  
이러한 방법이 단순무작위표집이 아닌 이유는 오직 일의 자리 수가 같은 10가지 경우만이 표집될 수 있기 때문이다. 단순무작위표집은 100명 중 10명을 완전 무작위로 뽑아야 한다.  
*(참고로 이처럼 번호를 매기고 특정 주기로 표집하는 방법은 계통표집(Systematic Sampling)이라고 한다.)*  

간단한 수학적 이야기를 덧붙이자면, 모집단의 크기가 $$N$$, 표본의 크기가 $$n$$일 때, 단순무작위표집에서 가능한 경우의 수는 $$_NC_n$$가지이다. 한편 단순무작위표집에서 특정한 대상이 표본에 들어있을 확률은 $${_{N-1}C_{n-1} \over _NC_n}$$이다. 가능한 모든 경우의 수($$_NC_n$$) 중에서 이미 우리가 바라는 하나가 표집되었고 나머지를 고르는 경우의 수($$_{N-1}C_{n-1}$$)를 세는 것이기 때문이다.  

한편, 또다른 확률표집 방법은 **집락표집(Cluster Sampling, 군집표집)**이다. 집락표집은 개개인(또는 개별 대상)을 표집하지 않는다. 우선 모집단을 몇 개의 그룹으로 분할한다. 그리고 그 그룹 단위로 표집하는 것이다. 예를 들어 서울 시민이 모집단이라면, 집락표집은 서울시를 구로 나누어서, 그중 하나를 골라 그 구만 표본으로 삼는 방법이다.  

집락표집과 비슷하지만 다른 방법으로 **층화표집(Stratified Sampling)**도 있다. 층화표집도 집락표집처럼 모집단을 몇 개의 그룹으로 나눈다. 하지만, 표집된 그룹만을 표본으로 사용하는 집락표집과 달리, 층화표집은 모든 그룹에서 조금씩 표집한 후 이를 하나로 합치는 방법을 사용한다. 예를 들어, 서울 시민을 구별로 나누었다면, 각 구에서 몇 명씩 뽑은 이후 이들을 모두 합쳐 표본으로 삼는 방법이 이에 해당한다.  

## Designed Experiment

우리는 때때로 특정한 요인(독립변수)이 다른 요인(종속변수)들에 영향을 미치는지 알고 싶어한다. 그럴 때 사용할 수 있는 방법들에 대해 알아보자.  

### Randomized Controlled Trial(RCT)

RCT란 실험집단과 통제집단을 무작위로 할당하는 방법이다. 어떻게 보면 표집 방법 중 단순무작위표집과 닮아있다. 실험집단에는 특정한 조치를 가하고, 통제집단에는 가하지 않은 채, 두 집단을 비교하여 효과를 확인한다. 임상시험 등에서 표준 급으로 쓰인다.  

### 관찰연구(Observational Study)

관찰연구는 연구자나 분석가가 직접적으로 처치를 할 수 없을 때 사용한다. 예를 들어 장기적인 흡연의 영향을 분석하고 싶다고 하자. 이를 위해 임상시험을 하듯이 RCT를 사용해서, 한쪽 집단은 담배를 피지 않게 하고, 한쪽 집단은 담배를 피게 하는 것은 윤리적으로나 현실적으로나 어려움이 많다. 따라서 이런 경우 흡연자와 비흡연자를 찾아 관찰하여 대조해야 할 것이다. 이것이 관찰연구이다.  

### A/B 테스트(A/B Testing)

A/B 테스트는 주로 마케팅 및 UI/UX 분야에서 자주 사용하는데, 두 가지 버전의 옵션을 만들어 이들을 비교하는 방법이다. 각 옵션에서 표집을 진행한 다음, 두 표본이 통계적으로 유의미한 차이를 보이는지(같은 모집단을 가지는 것으로 보이는지) 확인한다.  

# 정리

이 게시글에서는 데이터과학의 기초와 간단한 사전지식을 알아보았다. 특히 [표집](#표집sampling)에 대해서는 잘 알아둘 필요가 있다. 참고로 이건 기초 중에서도 극히 일부다. *기초적인 수준의* 자료구조, 알고리즘, 선형대수, 그리고 파이썬 문법 등을 미리 숙지하는 편이 도움이 될 것이다.  

다음 게시글에서는 `pandas`와 데이터프레임을 위주로 알아볼 예정이다.  