---
layout: posts
categories:
    - Study
title: (전공복습) 데이터과학 2. 전처리와 EDA
---

# 차례

- [차례](#차례)
- [들어가기 전에](#들어가기-전에)
- [분석을 시작하기 전에](#분석을-시작하기-전에)
- [전처리(Preprocessing)](#전처리preprocessing)
  - [데이터 클리닝(Data Cleaning)](#데이터-클리닝data-cleaning)
- [EDA](#eda)
  - [Structure](#structure)
    - [CSV, TSV](#csv-tsv)
    - [JSON](#json)
    - [XML](#xml)
    - [키(Key)와 조인(Join)](#키key와-조인join)
    - [변수의 종류](#변수의-종류)
      - [양적변수(Quantative Variable)](#양적변수quantative-variable)
      - [질적변수(Qualitative Variable)](#질적변수qualitative-variable)
  - [Granuality](#granuality)
  - [Scope](#scope)
  - [Temporality](#temporality)
  - [Faithfulness](#faithfulness)
- [정리](#정리)

# 들어가기 전에
> 이 글은 컴퓨터학과 이중전공생으로서 배운 것들을 다시 한번 정리하고자 남기는 글입니다. 불완전한 기억 등의 이유로 오류가 있을 수 있으며, 참조 내지 이정표로만 사용해주세요.  
> 본 게시글은 고려대학교의 *데이터과학* 강의를 기반으로 작성자의 추가적인 설명이 덧붙여진 글입니다.  

# 분석을 시작하기 전에

데이터 분석을 하기 전에, 우리는 무엇을 해야 할까? 우선 명확한 주제(문제의식)가 있어야 할 것이다. 내가 데이터를 통해 무엇을 알고 싶은지, 또는 무엇을 얻고 싶은지 명확히 할 필요가 있다. 또한, 데이터를 목적에 맞게 가공해야 할 것이다. 데이터의 구조가 항상 이상적이지는 않을 것이기 때문이다.  

# 전처리(Preprocessing)

데이터 분석 과정에서 우리가 얻은 원래 데이터는 **로 데이터(Raw Data)**라 부른다. 말 그대로 *날것의* 데이터인 셈이다. 이 데이터를 이해하고 분석하기 용이한 형태로 만드는 모든 과정을 데이터 전처리라 할 수 있다.  

## 데이터 클리닝(Data Cleaning)

데이터 전처리 과정 중, 결측값(누락된 값)이나 아웃라이어(Outlier, 이상치) 따위를 제거하거나 채워넣는 것을 **데이터 클리닝** 과정이라 한다.  

# EDA

**EDA(Exploratory Data Analysis)**는 우리말로 풀이하자면 *탐색적 데이터 분석*이라 할 수 있다. 그 이름처럼 EDA는 데이터를 탐색하기 위한 과정이다. 우리가 데이터 분석을 진행할 때, 언제나 명확한 문제를 가지고 시작하지는 않는다. 때로는 일련의 데이터에서 질문을 만들어내기도 하기 때문이다. 그렇다면 데이터에서 무언가 인싸이트를 얻어내야 하지 않겠는가? 그 과정이 바로 EDA라 할 수 있다.  

그렇다면 EDA는 어떻게 하는 것인가? 가장 간단한 방법은 데이터를 살펴보는 것이다. 이후에는 데이터의 총합이나 평균을 구해볼 수 있다(이러한 일을 하는 함수는 집계함수라 불린다). 시각화 또한 좋은 방법이다. 데이터의 시각적인 분포는 좋은 직관을 선물할 수 있다. 중요한 점이 있다면, EDA는 무언가 결론을 내리기 위한 것이 아니라는 점이다. 마치 탐정처럼, 데이터를 이리저리 살펴보며 흥미로운 점을 찾는 것이 EDA를 통해 하는 일이다.  

EDA는 *존 튜키(John Tukey)*라는 자가 도입하였다. 그는 대략적으로 아래와 같은 것들을 만들었다.  

- 고속 푸리에 변환(FFT) 알고리즘
- *비트(Bit)*라는 용어
- 박스플롯(Boxplot, 상자수염 그림)
- 튜키 사후검정(ANOVA에서 쓰는 그 Tukey 맞다)
- EDA

이러한 업적을 보면 알 수 있듯이, 수학, 통계학, 컴퓨터과학, 데이터과학 전반에 엄청난 기여를 한 사람인 셈이다. 아무튼, EDA라는 작업도 그의 발상이며, 그는 EDA를 *우리가 존재한다고 믿는 것은 물론이요, 존재하지 않는다고 믿는 것을 찾아내려는 태도, 유연성의 상태, 자발성*이라 하였다. 쉽게 말해, 목적을 가진 데이터 분석이 설계도를 그리고 그 설계도에 따라 무언가를 만드는 일이라면, EDA는 고무찰흙으로 이것저것 만들어도 보고, 부수어도 보면서 재료의 물성과 여러가지 아이디어를 실험해보는 일이라 할 수 있다.  

EDA 과정에서 신경쓰면 좋은 몇 가지 데이터의 속성(Property)들이 있다. 이를 알아보자.  

## Structure

데이터의 구조를 파악하는 것은 중요하다. 가장 편안한 구조는 사각형의(Rectangular) 구조이다. 대표적으로 **테이블(Table)**은 R이나 Python에서는 데이터프레임(Data Frame), SQL에서는 릴레이션(Relation) 따위의 표를 의미한다. 또한 **행렬(Matrix)** 역시 이러한 사각형의 2차원 데이터 구조라고 할 수 있다(데이터과학에서 선형대수가 얼마나 많이 쓰이는지 생각해보라).  
데이터 전처리 및 클리닝에서 중요한 작업 중 하나 역시 데이터를 이러한 사각형의 구조로 만드는 것이다. 이러한 구조를 저장하기 위한 파일로는 CSV, TSV, JSON, XML 등을 고려할 수 있다.  

### CSV, TSV

CSV(Comma Saparated Values)는 쉼표로, TSV(Tab Saparated Values)는 탭으로 각 값들이 구분된 파일 형식을 의미한다. 각 행은 개행 문자(`\n` 또는 `\r\n`, 즉 엔터)으로 구분되고, 각 열은 쉼표(`,`)나 탭(`  `)으로 구분된다. 예를 들어 아래는 아주 간단한 CSV 형식의 예제이다.  

```csv
이름,나이,성격
김00,20,온화함
이00,32,신경질적임
```

이처럼 개행과 쉼표 또는 탭으로 각 값들을 구분하는 양식을 CSV 또는 TSV라 한다. 물론 구분자로는 어떤 문자든 사용할 수 있다.  
어떤 문자를 구분자로 사용하든, 이런 양식에서 주의해야 할 점은 값에 구분자와 같은 문자가 들어갈 수 있다는 점이다. 이 경우는 보통 구분자를 포함한 값을 따옴표(`""`)로 둘러싸게 되지만, 이 경우 따옴표가 값 안에 못 들어간다는 문제가 발생한다. 이러한 문제를 해결하는 방법은 따옴표를 `""`나 `\"`와 같이 이스케이프하여 사용하는 것이다.  

### JSON

JSON은 Javascript Object Notation의 줄임말이다. 쉽게 말해, 자바스크립트의 객체 문법을 따르는 데이터 구조이다. 예를 들어 아래는 JSON의 예시이다.  

```json
{
    "키는 무조건": "값",
    "문자열이지만": [
        "값은 배열",
        1,
        "숫자",
        true,
        "부울 등 다양한 값이 가능하다"
    ]
}
```

JSON으로 구현된 테이블은 항상 테이블의 조건을 만족하지 않으며, 정규성을 위반할 가능성도 크다는 것을 고려하라. 예를 들어서, JSON 객체의 값에는 배열이나 또다른 객체가 올 수 있다.  
*(정규성에 관한 것은 추후 작성될 데이터베이스 게시글을 참조하라.)*  

### XML

XML은 eXtensible Markup Language를 의미한다. HTML과 비슷한 형태로 생겼으며, JSON과 마찬가지로 데이터의 형태가 항상 테이블의 형태임은 보장할 수 없다. 아래는 XML의 예시이다.  

```xml
<kimchi>
    <baechu>
        <taste>good</taste>
        <color>red</color>
    </baechu>
</kimchi>
```

### 키(Key)와 조인(Join)

때때로 데이터는 다른 데이터를 참조한다. 예를 들어, `강의` 테이블에는 수업에 대한 데이터가 들어 있다고 할 때, 아래와 같이 강의를 진행하는 건물을 참조할 수 있다.  

|번호|강의명|건물명|
|-|-|-|
|0|데이터과학|정보관|
|1|하이퍼텍스트와계산가능성|교양관|
|2|이산수학|정보관|
|3|사회통계|서관|

이때, `건물` 테이블은 아래와 같을 수 있다.  

|건물명|용도|
|-|-|
|정보관|정보대 아지트|
|교양관|교양수업|
|서관|문과대 아지트|
|서관|생과대 아지트|

이 경우, `강의` 테이블은 `건물` 테이블을 참조하고 있는 셈이다. 그런데, 위 테이블을 보면 알 수 있다시피 `서관`이 두 번 등장한다. 그렇다면 `강의` 테이블에서 참조하는 `서관`은 첫 번째 `서관`인가 두 번째 `서관`인가? 이처럼 테이블에서 다른 테이블을 참조할 때, 참조 대상이 되는 열은 고유해야 한다. 즉, 아래와 같이 바꿔주어야 `건물` 테이블의 `건물명` 열이 각 행을 식별하는 데에 사용될 수 있다.  

|건물명|용도|
|-|-|
|정보관|정보대 아지트|
|교양관|교양수업|
|문과대 서관|문과대 아지트|
|생과대 서관|생과대 아지트|

이렇게 `건물` 테이블의 `건물명`처럼 그 행을 식별할 수 있도록 해주는 열을 **기본키(Primary Key)**라고 한다. 한편, `강의` 테이블의 `건물명`처럼 다른 테이블의 기본키를 참조하는 열을 **외래키(Foregin Key)**라고 한다. 이때, 두 테이블을 기본키와 외래키를 이용해 합칠 수 있는데, 대략 이런 모습일 것이다.  

|번호|강의명|건물명|용도|
|-|-|-|-|
|0|데이터과학|정보관|정보대 아지트|
|1|하이퍼텍스트와계산가능성|교양관|교양수업|
|2|이산수학|정보관|정보대 아지트|
|3|사회통계|문과대 서관|문과대 아지트|

이처럼, 여러 개의 테이블을 특정 열을 기준으로 하나로 합치는 행위를 **조인(Join)**이라 한다.  
*(키와 조인에 관한 내용은 추후 다룰 데이터베이스 강의에서 자세하게 설명될 것이다.)*  

### 변수의 종류

우리는 지난 판다스(Pandas) 게시글에서 [데이터프레임](https://su5468.github.io/study/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99_1/#%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84dataframe)을 다루면서, 각 열은 타입을 갖는다고 배웠다. 예를 들어, `번호` 열은 아마 정수일 것이고, `이름` 열은 아마 문자열일 것이다. 이러한 변수들을 몇 가지 기준에 따라 구분할 수 있는데, 대략적으로 아래와 같다.  

- 양적변수(Quantative)
  - 연속변수(Continuous)
  - 이산변수(Discrete)
- 질적변수(Qualitative)
  - 순서변수(Ordinal)
  - 명목변수(Nominal)

*(각 변수 또는 척도의 종류는 정말 나중에야 다루게 될 수도 있는 사회조사방법론 게시글에서 더 자세히 설명될 수도 있다.)*  

#### 양적변수(Quantative Variable)

양적변수란 말 그대로 수치형의 변수를 의미한다. 양적변수는 또 크게 두 가지로 나뉘어진다.  

- **연속변수(Continuous Variable)**: 값들이 연속적인, 쉽게 말해 실수 형태의 변수이다.
  - ex. 온도, 키, 몸무게, ...
- **이산변수(Discrete Variable)**: 값들이 이산적인, 즉 셀 수 있는 정수 형태의 변수이다.
  - ex. 나이, 가구수, ...

#### 질적변수(Qualitative Variable)

반대로 질적변수란 수치형이 아닌 변수를 의미한다. 질적변수 역시 두 가지로 나뉘어질 수 있다.

- **순서변수(Ordinal Varaible)**: 값들이 순위를 가지는 변수이다.
  - 선호도, 소득구간, ...
- **명목변수(Nominal Variable)**: 순서나 상하관계가 없는 변수이다.
  - 이름, 성별, 거주지, ...

## Granuality

구조 외에 EDA 시에 고려할 수 있는 요소는 바로 Granuality다. 우리말로는 *세분성* 정도로 해석할 수 있는데, 쉽게 이야기해 *알갱이의 크기* 정도로 생각하면 된다. 고운 모래는 세분성이 높고, 굵은 자갈은 세분성이 낮은 셈이다.  

세분성은 쉽게 말해 각 행이 원자적으로 다루는 대상(단위)이 무엇이냐 하는 점이다. 이를테면, 아래 테이블에서 각 행의 단위는 `세대`이다.  

|번호|세대주|월소득|
|-|-|-|
|0|김00|3,000,000|
|1|이00|4,000,000|
|2|박00|4,300,000|

반면, 아래 테이블에서 각 행의 단위는 `개인`이다.  

|번호|이름|월소득|
|-|-|-|
|0|김00|1,500,000|
|1|이00|2,000,000|
|2|박00|3,000,000|

당연하지만 두 테이블의 세분성이 다르기 때문에, 두 `월소득` 열의 의미도 달라진다. 한쪽은 세대의 월소득이며, 한쪽은 개인의 월소득이다. 세분성을 고려하여야 두 데이터를 조인할 때 문제가 생길 여지가 줄어든다.  
또한, 일부 데이터에는 합계나 평균 같은 집계결과가 들어가 있을 수 있음에 유의하라. 이러한 데이터는 당연히 다른 데이터와 다른 세분성을 지니므로 빠져야 할 것이다.  
만약 데이터의 세분성이 낮다면 집계 방식 역시 유의해야 한다. 어떤 데이터는 합계를, 어떤 데이터는 평균을, 어떤 데이터는 최댓값을 나타낸다면 비교가 곤란해진다.  

## Scope

Scope는 영역이라는 뜻이다. 데이터가 지시하는 영역이 내 관심 영역과 일치하는가? 내가 알고 싶은 건 *대한민국의* 데이터인데, 가진 데이터가 *서울 지역의* 데이터라면, 불일치가 있음을 인지해야 한다. 반대의 경우 역시 마찬가지다. *대한민국의* 데이터에서 어떻게 *서울 지역의* 데이터를 뽑아낼까? `거주지`와 같은 열이 있다면 상관 없겠지만, 그렇지 않은 경우 어떻게 추출이 가능한가?  

이 문제는 지난번에 이야기한 [표집틀의 문제](https://su5468.github.io/study/%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99_0/#%ED%91%9C%EC%A7%91sampling)와도 연관성이 있다. 표집틀이 모집단에 부합하는가? 즉, 데이터가 연구주제에 부합하는가? 이 역시 중요한 질문이다.  

## Temporality

말 그대로 시간에 관한 측면이다. 데이터는 언제 모아졌는가? 2000년대 초반의 데이터가 현재를 대표할 수 있는가? 만약 시계열 데이터를 획득했다면, 데이터의 타임스탬프는 무엇을 의미하는가? 사건이 발생한 시간? 데이터가 수집된 시간? 혹은 시스템에 기록된 시간?  
또한 흥미로운 점은, 수집 위치에 따라 시간이 변화한다는 점이다. 타임존(Timezone)을 고려했는가? 일광 시간제(Daylight Saving)는 어떤가?  
당연히 널(Null) 값으로 보아야 하는 특이한 값들도 생각해야 한다. `1970.01.01 00:00:00`은 진짜 그 날짜가 아니라 결측값으로서의 유닉스 시간 `0`을 의미하는 것일 수도 있다. `1900.01.01`과 같은 값 역시 마찬가지이다.  

## Faithfulness

데이터가 항상 옳지는 않다. 데이터는 인간에 의해 수집된다. 데이터를 기록하고 저장하는 시스템은 인간에 의해 운영된다. 그리고, 인간은 항상 실수를 한다.  
혹시 생년월일이 미래로 되어있지는 않은가? 출생지가 아무것도 없는 망망대해의 좌표는 아닌가? 개수가 음수는 아닌가? 이름에 오탈자는 없는가? 아무리 생각해도 이상한 값(아웃라이어, Outlier)가 있지는 않은가?  
각 열들의 관계에 문제가 있을 수도 있다. 태어난 날과 나이가 알맞게 계산되었는가? 성별이 여성인데 주민등록번호가 1로 시작하지는 않는가? 손으로 데이터를 기록하는 과정에서 오류가 나거나 설문조사에 응답자가 불성실하게 대답한 것으로 보이는 값이 들어있지는 않은가?  

잘못된 값이나 결측값을 어떻게 처리할 수 있는가? 첫 번째 방법은 결측값이 들어있는 행 전체를 누락(Drop)시켜 버리는 것이다. 하지만 결측값에 일정한 경향이 있는 경우 이러한 누락은 편향을 부를 수 있다. 어쩌면 특정 성향의 값들이 누락되었다는 사실이 어떠한 증거일 수 있다.  
두 번째는 결측값을 대치(Imputation)하는 것이다. 쉽게 말해 다른 값으로 대체하는 것인데, 평균이나 중간값, 최빈값을 사용할 수도 있고, 다른 통계적 방법을 이용해 값을 샘플링할 수도 있다.  
어떤 때는 그냥 놔두는 게 답일 수도 있다. 모델에 따라 결측값을 나름대로 처리할 수 있는 경우도 있고, 범주형 변수에서 결측값을 하나의 범주로 사용할 수도 있다.  
이러한 문제에는 하나의 고정된 정답이 없다. 중요한 것은, 도메인 지식과 통계적 추론을 이용해 가장 좋은 방법이 무엇일지 고려하는 것이다.  

# 정리

오늘은 데이터과학에서 행해지는 전처리와 EDA에 대해 간략하게 다루어 보았다.  

다음에는 정규표현식과 시각화에 대해 다루게 되며, 그 이후 각종 기계학습 모형(Model, 모델)들을 살펴볼 것이다(인공지능 또는 추후 다루게 될 기계학습 강의와 중복되는 내용이 다소 있을 수 있다).  